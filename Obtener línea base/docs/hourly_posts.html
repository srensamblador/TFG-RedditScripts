<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.4" />
<title>hourly_posts API documentation</title>
<meta name="description" content="Script para obtener el número de post por hora en el índice de Elasticsearch
Sobre un índice de Elasticsearch especificado, se obtiene el número de …" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>hourly_posts</code></h1>
</header>
<section id="section-intro">
<h2 id="script-para-obtener-el-numero-de-post-por-hora-en-el-indice-de-elasticsearch">Script para obtener el número de post por hora en el índice de Elasticsearch</h2>
<p>Sobre un índice de Elasticsearch especificado, se obtiene el número de posts en cada intervalo de una hora.<br>
La lista de datos resultante se serializa en un fichero con el siguiente formato:<br>
TimestampInicial;TimestampFinal;NúmeroPosts</p>
<h2 id="parametros">Parámetros</h2>
<ul>
<li>-e, &ndash;elasticsearch: dirección del servidor Elasticsearch. Por defecto, <a href="http://localhost:9200">http://localhost:9200</a></li>
<li>-i, &ndash;index: nombre del índice sobre el que realizarán las consultas. Por defecto, "reddit-loneliness"</li>
<li>-o, &ndash;output: fichero donde se serializarán los resultados. Por defecto, "hourly_posts.csv"</li>
</ul>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#!/usr/bin/env python
&#34;&#34;&#34;
    Script para obtener el número de post por hora en el índice de Elasticsearch
    ----------------------------------------------------------------------------
    Sobre un índice de Elasticsearch especificado, se obtiene el número de posts en cada intervalo de una hora.  
    La lista de datos resultante se serializa en un fichero con el siguiente formato:  
        TimestampInicial;TimestampFinal;NúmeroPosts
    
    Parámetros
    ----------
    * -e, --elasticsearch: dirección del servidor Elasticsearch. Por defecto, http://localhost:9200
    * -i, --index: nombre del índice sobre el que realizarán las consultas. Por defecto, &#34;reddit-loneliness&#34;
    * -o, --output: fichero donde se serializarán los resultados. Por defecto, &#34;hourly_posts.csv&#34;
&#34;&#34;&#34;

from elasticsearch import Elasticsearch
import argparse
from datetime import datetime, timedelta

__author__ = &#34;Samuel Cifuentes García&#34;

def main(args):
    # Conexión a Elastic
    global es
    es = Elasticsearch(args.elasticsearch)
    
    # Se obtienen las fechas límite
    dates = get_boundary_dates(args.index)

    print(&#34;Procesando documentos...&#34;)
    submissions_per_hour = []
    after_date = dates[1]
    while after_date &gt; dates[0]:
        # Para cada intervalo de una hora se obtiene el número de posts
        before_date = after_date - timedelta(hours=1)
        
        # Cada vez que se complete un año se muestra por consola para tener feedback
        if before_date.day == 1 and before_date.month == 1 and before_date.hour == 0:
            print(before_date)

        count = get_submission_count(before_date.timestamp(), after_date.timestamp(), args.index)
        # Si un intervalo no tiene post no se incluye
        if count &gt; 0:
            submissions_per_hour.append((before_date.timestamp(), after_date.timestamp(), count))

        after_date = before_date
    
    # Guardamos los resultaods en el archivo especificado
    print(&#34;Serializando en &#34; + args.output + &#34;...&#34;)
    write_to_csv(args.output, submissions_per_hour)

    print(&#34;Completado&#34;)
        
def get_boundary_dates(index):
    &#34;&#34;&#34;
        Obtiene la fecha más reciente y la más antigua presente en el índice. 
        Para ello se emplean agregaciones de máximo y mínimo sobre el campo created_utc de los
        documentos.

        Parámetros
        ----------
        index: str
            nombre del índice sobre el que consultar

        Salida
        ------
        oldest_date: datetime
            fecha más antigua presente en el índice
        newest_date: datetime
            fecha más reciente presente en el ínndice

    &#34;&#34;&#34;
    query = {
        &#34;size&#34;: 0,
        &#34;aggs&#34;: {
            &#34;oldest_date&#34;: {
                &#34;min&#34;: {
                    &#34;field&#34;: &#34;created_utc&#34;
                }
            },
            &#34;newest_date&#34;: {
                &#34;max&#34;: {
                    &#34;field&#34;: &#34;created_utc&#34;
                }
            }
        }
    }
    res = es.search(
        index=index,
        body=query
    )

    oldest_date = res[&#34;aggregations&#34;][&#34;oldest_date&#34;][&#34;value&#34;]
    newest_date = res[&#34;aggregations&#34;][&#34;newest_date&#34;][&#34;value&#34;]

    # Redondeamos los timestamp a horas exactas
    oldest_date = datetime.fromtimestamp(oldest_date)
    oldest_date = oldest_date.replace(minute=0, second=0, microsecond=0)

    newest_date = datetime.fromtimestamp(newest_date)
    newest_date = (newest_date + timedelta(hours=1)
                   ).replace(minute=0, second=0, microsecond=0)

    return oldest_date, newest_date


def get_submission_count(before_timestamp, after_timestamp, index):
    &#34;&#34;&#34;
        Recupera el número de documentos en un índice en el intervalo de tiempo especificado.
        Se utiliza la API Count: https://www.elastic.co/guide/en/elasticsearch/reference/current/search-count.html,
        ya que es más eficiente que contar el número de hits en una consulta Search

        Parámetros
        ----------
        before_timestamp: int
            timestamp de la fecha inicial del intervalo
        after_timestamp: int
            timestamp de la fecha final del intervalo
        index: str
            nombre del índice

        Salida
        ------
        count: int
            número de posts en el intervalo temporal
    &#34;&#34;&#34;
    query = {
        &#34;query&#34;: {
            &#34;range&#34;: {
                &#34;created_utc&#34;: {
                    &#34;gte&#34;: before_timestamp,
                    &#34;lte&#34;: after_timestamp
                }
            }
        }
    }
     
    res = es.count(
        index=index,
        body=query
    )
    return res[&#34;count&#34;]

def write_to_csv(filename, submissions):
    &#34;&#34;&#34;
        Vuelca una lista de post por intervalo de tiempo al fichero especificado. Cada elemento de la lista será
        una tupla de la forma:  
            (TimestampInicio,TimestampFinal,NumPosts)

        Parámetros
        ----------
        filename: str
            nombre del fichero  donde se serializarán los datos
        submissions: list of tuples
            lista de tuplas con los datos a serializar
    &#34;&#34;&#34;
    with open(filename, &#34;w&#34;) as f:
        for tuple in submissions:
            f.write(&#34;;&#34;.join([str(x) for x in tuple]) + &#34;\n&#34;)


def parse_args():
    &#34;&#34;&#34;
        Procesamiento de los argumentos con los que se ejecutó el script
    &#34;&#34;&#34;
    parser = argparse.ArgumentParser(
        description=&#34;Script para obtener el número de post por hora en Elastic&#34;)
    parser.add_argument(&#34;-e&#34;, &#34;--elasticsearch&#34;, default=&#34;http://localhost:9200&#34;,
                        help=&#34;dirección del servidor Elasticsearch&#34;)
    parser.add_argument(&#34;-i&#34;, &#34;--index&#34;, default=&#34;reddit-loneliness&#34;,
                        help=&#34;nombre del índice a procesar&#34;)                        
    parser.add_argument(&#34;-o&#34;, &#34;--output&#34;, default=&#34;hourly_posts.csv&#34;,
                        help=&#34;Archivo donde se almacenarán los resultados&#34;)
    return parser.parse_args()


if __name__ == &#34;__main__&#34;:
    main(parse_args())</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="hourly_posts.get_boundary_dates"><code class="name flex">
<span>def <span class="ident">get_boundary_dates</span></span>(<span>index)</span>
</code></dt>
<dd>
<section class="desc"><p>Obtiene la fecha más reciente y la más antigua presente en el índice.
Para ello se emplean agregaciones de máximo y mínimo sobre el campo created_utc de los
documentos.</p>
<h2 id="parametros">Parámetros</h2>
<dl>
<dt><strong><code>index</code></strong> :&ensp;<code>str</code></dt>
<dd>nombre del índice sobre el que consultar</dd>
</dl>
<h2 id="salida">Salida</h2>
<dl>
<dt><strong><code>oldest_date</code></strong> :&ensp;<code>datetime</code></dt>
<dd>fecha más antigua presente en el índice</dd>
<dt><strong><code>newest_date</code></strong> :&ensp;<code>datetime</code></dt>
<dd>fecha más reciente presente en el ínndice</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_boundary_dates(index):
    &#34;&#34;&#34;
        Obtiene la fecha más reciente y la más antigua presente en el índice. 
        Para ello se emplean agregaciones de máximo y mínimo sobre el campo created_utc de los
        documentos.

        Parámetros
        ----------
        index: str
            nombre del índice sobre el que consultar

        Salida
        ------
        oldest_date: datetime
            fecha más antigua presente en el índice
        newest_date: datetime
            fecha más reciente presente en el ínndice

    &#34;&#34;&#34;
    query = {
        &#34;size&#34;: 0,
        &#34;aggs&#34;: {
            &#34;oldest_date&#34;: {
                &#34;min&#34;: {
                    &#34;field&#34;: &#34;created_utc&#34;
                }
            },
            &#34;newest_date&#34;: {
                &#34;max&#34;: {
                    &#34;field&#34;: &#34;created_utc&#34;
                }
            }
        }
    }
    res = es.search(
        index=index,
        body=query
    )

    oldest_date = res[&#34;aggregations&#34;][&#34;oldest_date&#34;][&#34;value&#34;]
    newest_date = res[&#34;aggregations&#34;][&#34;newest_date&#34;][&#34;value&#34;]

    # Redondeamos los timestamp a horas exactas
    oldest_date = datetime.fromtimestamp(oldest_date)
    oldest_date = oldest_date.replace(minute=0, second=0, microsecond=0)

    newest_date = datetime.fromtimestamp(newest_date)
    newest_date = (newest_date + timedelta(hours=1)
                   ).replace(minute=0, second=0, microsecond=0)

    return oldest_date, newest_date</code></pre>
</details>
</dd>
<dt id="hourly_posts.get_submission_count"><code class="name flex">
<span>def <span class="ident">get_submission_count</span></span>(<span>before_timestamp, after_timestamp, index)</span>
</code></dt>
<dd>
<section class="desc"><p>Recupera el número de documentos en un índice en el intervalo de tiempo especificado.
Se utiliza la API Count: <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-count.html,">https://www.elastic.co/guide/en/elasticsearch/reference/current/search-count.html,</a>
ya que es más eficiente que contar el número de hits en una consulta Search</p>
<h2 id="parametros">Parámetros</h2>
<dl>
<dt><strong><code>before_timestamp</code></strong> :&ensp;<code>int</code></dt>
<dd>timestamp de la fecha inicial del intervalo</dd>
<dt><strong><code>after_timestamp</code></strong> :&ensp;<code>int</code></dt>
<dd>timestamp de la fecha final del intervalo</dd>
<dt><strong><code>index</code></strong> :&ensp;<code>str</code></dt>
<dd>nombre del índice</dd>
</dl>
<h2 id="salida">Salida</h2>
<dl>
<dt><strong><code>count</code></strong> :&ensp;<code>int</code></dt>
<dd>número de posts en el intervalo temporal</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_submission_count(before_timestamp, after_timestamp, index):
    &#34;&#34;&#34;
        Recupera el número de documentos en un índice en el intervalo de tiempo especificado.
        Se utiliza la API Count: https://www.elastic.co/guide/en/elasticsearch/reference/current/search-count.html,
        ya que es más eficiente que contar el número de hits en una consulta Search

        Parámetros
        ----------
        before_timestamp: int
            timestamp de la fecha inicial del intervalo
        after_timestamp: int
            timestamp de la fecha final del intervalo
        index: str
            nombre del índice

        Salida
        ------
        count: int
            número de posts en el intervalo temporal
    &#34;&#34;&#34;
    query = {
        &#34;query&#34;: {
            &#34;range&#34;: {
                &#34;created_utc&#34;: {
                    &#34;gte&#34;: before_timestamp,
                    &#34;lte&#34;: after_timestamp
                }
            }
        }
    }
     
    res = es.count(
        index=index,
        body=query
    )
    return res[&#34;count&#34;]</code></pre>
</details>
</dd>
<dt id="hourly_posts.main"><code class="name flex">
<span>def <span class="ident">main</span></span>(<span>args)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def main(args):
    # Conexión a Elastic
    global es
    es = Elasticsearch(args.elasticsearch)
    
    # Se obtienen las fechas límite
    dates = get_boundary_dates(args.index)

    print(&#34;Procesando documentos...&#34;)
    submissions_per_hour = []
    after_date = dates[1]
    while after_date &gt; dates[0]:
        # Para cada intervalo de una hora se obtiene el número de posts
        before_date = after_date - timedelta(hours=1)
        
        # Cada vez que se complete un año se muestra por consola para tener feedback
        if before_date.day == 1 and before_date.month == 1 and before_date.hour == 0:
            print(before_date)

        count = get_submission_count(before_date.timestamp(), after_date.timestamp(), args.index)
        # Si un intervalo no tiene post no se incluye
        if count &gt; 0:
            submissions_per_hour.append((before_date.timestamp(), after_date.timestamp(), count))

        after_date = before_date
    
    # Guardamos los resultaods en el archivo especificado
    print(&#34;Serializando en &#34; + args.output + &#34;...&#34;)
    write_to_csv(args.output, submissions_per_hour)

    print(&#34;Completado&#34;)</code></pre>
</details>
</dd>
<dt id="hourly_posts.parse_args"><code class="name flex">
<span>def <span class="ident">parse_args</span></span>(<span>)</span>
</code></dt>
<dd>
<section class="desc"><p>Procesamiento de los argumentos con los que se ejecutó el script</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_args():
    &#34;&#34;&#34;
        Procesamiento de los argumentos con los que se ejecutó el script
    &#34;&#34;&#34;
    parser = argparse.ArgumentParser(
        description=&#34;Script para obtener el número de post por hora en Elastic&#34;)
    parser.add_argument(&#34;-e&#34;, &#34;--elasticsearch&#34;, default=&#34;http://localhost:9200&#34;,
                        help=&#34;dirección del servidor Elasticsearch&#34;)
    parser.add_argument(&#34;-i&#34;, &#34;--index&#34;, default=&#34;reddit-loneliness&#34;,
                        help=&#34;nombre del índice a procesar&#34;)                        
    parser.add_argument(&#34;-o&#34;, &#34;--output&#34;, default=&#34;hourly_posts.csv&#34;,
                        help=&#34;Archivo donde se almacenarán los resultados&#34;)
    return parser.parse_args()</code></pre>
</details>
</dd>
<dt id="hourly_posts.write_to_csv"><code class="name flex">
<span>def <span class="ident">write_to_csv</span></span>(<span>filename, submissions)</span>
</code></dt>
<dd>
<section class="desc"><p>Vuelca una lista de post por intervalo de tiempo al fichero especificado. Cada elemento de la lista será
una tupla de la forma:<br>
(TimestampInicio,TimestampFinal,NumPosts)</p>
<h2 id="parametros">Parámetros</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>nombre del fichero
donde se serializarán los datos</dd>
<dt><strong><code>submissions</code></strong> :&ensp;<code>list</code> of <code>tuples</code></dt>
<dd>lista de tuplas con los datos a serializar</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_to_csv(filename, submissions):
    &#34;&#34;&#34;
        Vuelca una lista de post por intervalo de tiempo al fichero especificado. Cada elemento de la lista será
        una tupla de la forma:  
            (TimestampInicio,TimestampFinal,NumPosts)

        Parámetros
        ----------
        filename: str
            nombre del fichero  donde se serializarán los datos
        submissions: list of tuples
            lista de tuplas con los datos a serializar
    &#34;&#34;&#34;
    with open(filename, &#34;w&#34;) as f:
        for tuple in submissions:
            f.write(&#34;;&#34;.join([str(x) for x in tuple]) + &#34;\n&#34;)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#script-para-obtener-el-numero-de-post-por-hora-en-el-indice-de-elasticsearch">Script para obtener el número de post por hora en el índice de Elasticsearch</a></li>
<li><a href="#parametros">Parámetros</a></li>
</ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="hourly_posts.get_boundary_dates" href="#hourly_posts.get_boundary_dates">get_boundary_dates</a></code></li>
<li><code><a title="hourly_posts.get_submission_count" href="#hourly_posts.get_submission_count">get_submission_count</a></code></li>
<li><code><a title="hourly_posts.main" href="#hourly_posts.main">main</a></code></li>
<li><code><a title="hourly_posts.parse_args" href="#hourly_posts.parse_args">parse_args</a></code></li>
<li><code><a title="hourly_posts.write_to_csv" href="#hourly_posts.write_to_csv">write_to_csv</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.4</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>